{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tMuBsWaNeXFo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,random_split,Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "with open(\"/content/drive/MyDrive/Data/Persian-WikiText-1.txt\") as f :\n",
        "  l = f.readlines()"
      ],
      "metadata": {
        "id": "lg2isrgcehJe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "texts = [re.sub(r'[^\\w]',' ',t) for t in l]\n",
        "print(texts[40])\n",
        "print(\"---\")\n",
        "texts = [re.sub(r'\\s+',' ',t) for t in texts]\n",
        "print(texts[40])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YiAc9Rj95Iz",
        "outputId": "1dbbf57e-1d30-4607-c92b-79dc331e6fa3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "---\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts  = [t for t in texts if t not in [' ', '\\n']]"
      ],
      "metadata": {
        "id": "net1ZrN4_D7v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [re.sub(r'^\\s','',t) for t in texts];\n",
        "texts = [re.sub(r'\\s$','',t) for t in texts];"
      ],
      "metadata": {
        "id": "21ofrqYO_MrG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "rbQJkeOK_cqf",
        "outputId": "6df7d63b-1504-4e00-8722-c1f3d4e7e3f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ویکی پدیا از پایان آوریل ۲۰۰۷ تا اکتبر ۲۰۱۹ یکی از ۱۰ وبگاه برتر جهان از لحاظ شمار بازدیدکنندگان بوده است که بیش از نیمی از بازدیدها به ویکی پدیای انگلیسی مربوط می شود'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM,DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "bDijrPb99yro"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "eIRlp9w9FdAq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'HooshvareLab/bert-fa-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IZauGIS9ai_",
        "outputId": "49e85600-e1a1-44fe-becb-3fd825af2399"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(len(t.split()) for t in texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmOOikAlBI50",
        "outputId": "9bc8b779-9bf5-40c4-eccf-50631661e17f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1842"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Text(Dataset):\n",
        "  def __init__(self, texts, tokenizer):\n",
        "    super().__init__() ;\n",
        "    self.texts = texts;\n",
        "    self.tokenizer = tokenizer;\n",
        "  def __len__(self): return len(self.texts);\n",
        "  def __getitem__(self, index):\n",
        "    text = self.texts[index];\n",
        "    tokens = self.tokenizer(text,truncation=True,max_length=256,padding='max_length',return_tensors='pt');\n",
        "    item = {key:val.squeeze(0) for key,val in tokens.items()};\n",
        "    return item"
      ],
      "metadata": {
        "id": "9gNUJUtdAcOa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Text(texts,tokenizer);\n",
        "dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXQV5dpkBxU3",
        "outputId": "e1989fad-9e6c-47e6-ccb9-f985144f6102"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([    2,  1379,  2880,  4207,  3212, 51278, 32824,  3500,  2789,  2867,\n",
              "          2830, 51278, 32824,  4484, 13494,  6552,  1379, 18879,  2003,  2834,\n",
              "          2800,  6012,  8278,  3158,  5613,  1379,  2791,  3626,  2829,  3877,\n",
              "          4259,  4196,  2793,  3589, 51278, 32824,  2786,  3378,  1463,  6023,\n",
              "          6912,  3032,  5667, 13994,  3671,  7959,  3052,  6166,  2017,  2800,\n",
              "          2829,  3052, 30122,  4670,  2834,  6130,  4604,  2817,  3052,  6166,\n",
              "          2017,  2800,  2786,  2844, 10155,  6130,  4604,  2871,  2834,  2829,\n",
              "          4795,  6825, 13070, 35008,  1379,  3450,  7443,  5172,  2831,  5590,\n",
              "          2834,  1379,  3497,  3923, 13494,  3912, 51278, 32824,  1379,  7233,\n",
              "          2808, 12570, 47975,  3158,  2808,  2848,  2844,  8043,  3823,  2793,\n",
              "          2817,  9908,  6715,  1379,  9258,  2988,  2871,  2831,  4484, 12570,\n",
              "         47975,  3158,  6166,  2017,  4624,  2817,  1379,  3398,  2791,  8276,\n",
              "          3052,  6166,  2017,  1379,  2921,  5471,  2802,  3052,  2786,  3280,\n",
              "          4461, 12570, 47975,  3909,  3380,  4296,  6076, 51278, 32824,  4226,\n",
              "          3339,  2791, 14909, 41198,  3411,  3052,  1379,  3835,  9876,  5035,\n",
              "          1379, 14409,  1364,  3682,  1362,  3411,  3108,  9341,  1379, 14073,\n",
              "         51278, 32824,  1379,  5617, 12570, 47975, 16468,  2802,  3897, 51278,\n",
              "         32824,  2803,  5755,  2793,  3054,  2800,  3016,  3437, 13494,  6343,\n",
              "          3731,  2808,  3146,  3327, 51278, 32824,  3450,  5358,  3912,  2834,\n",
              "          1379,  6377,  4205,  4379,  4140,  3040,  4900,  2959,  2996, 14375,\n",
              "          2789,  3804,  8468,  3885,  1379,  6510,  5223,  3052,  6299, 10538,\n",
              "          2847,  2883,  3583,  2834, 51278, 32824,  3450,  4071,  4280, 10758,\n",
              "          3158,  5613,  5586,  2786,  3665,  6343,  3431,  2834,  3362,  5617,\n",
              "         11227,  2789,  2802,  4686,  8442,  2800,  2802,  4393,  2831,  3114,\n",
              "          6012,  5929,  3177,  3054,  2806,  3052,  6166,  2017,  2800,  4517,\n",
              "          7151,  2802, 13494,  2834,  6650,     4]),\n",
              " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GF2ymew1CPpC",
        "outputId": "37042915-2443-48ac-b6d3-492f1a445b0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "212623"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "collate = DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=True,mlm_probability=0.15);"
      ],
      "metadata": {
        "id": "3wgYMnBlCito"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset,val_dataset = random_split(dataset,[200000,12623])\n",
        "train_loader = DataLoader(train_dataset,batch_size=4,shuffle=True,collate_fn=collate);\n",
        "val_loader = DataLoader(val_dataset,batch_size=4,shuffle=False,collate_fn =collate);"
      ],
      "metadata": {
        "id": "bjybiBsYCMnQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForMaskedLM.from_pretrained(model_name);\n",
        "device = 'cuda'\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsT4goQwDmr-",
        "outputId": "31879671-8274-4699-dbfd-aded838282b4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=100000, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(lr = 1e-5,params = model.parameters())\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=-100);"
      ],
      "metadata": {
        "id": "8AcK7TlFDwlm"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = 0;\n",
        "model.train()\n",
        "for x in train_loader :\n",
        "  optimizer.zero_grad();\n",
        "  input_ids = x['input_ids'].to(device);\n",
        "  attention_mask = x['attention_mask'].to(device);\n",
        "  labels = x['labels'].to(device);\n",
        "  out = model(input_ids = input_ids,attention_mask = attention_mask,labels=labels);\n",
        "  loss = out.loss\n",
        "  loss.backward();\n",
        "  optimizer.step();\n",
        "  b+=1;\n",
        "  if (b%10==0): print(f\"Iteration {b} ---> Loss {round(loss.item(),4)}\");\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yKf6jjahDKiY",
        "outputId": "c61afcc5-8716-4052-dc6f-1d9dd87502c4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10 ---> Loss 8.2909\n",
            "Iteration 20 ---> Loss 8.0047\n",
            "Iteration 30 ---> Loss 6.1657\n",
            "Iteration 40 ---> Loss 3.8094\n",
            "Iteration 50 ---> Loss 4.7057\n",
            "Iteration 60 ---> Loss 3.9707\n",
            "Iteration 70 ---> Loss 1.8695\n",
            "Iteration 80 ---> Loss 2.0591\n",
            "Iteration 90 ---> Loss 3.7987\n",
            "Iteration 100 ---> Loss 2.7061\n",
            "Iteration 110 ---> Loss 3.7735\n",
            "Iteration 120 ---> Loss 3.2304\n",
            "Iteration 130 ---> Loss 4.5588\n",
            "Iteration 140 ---> Loss 2.7743\n",
            "Iteration 150 ---> Loss 2.6107\n",
            "Iteration 160 ---> Loss 2.1651\n",
            "Iteration 170 ---> Loss 3.1968\n",
            "Iteration 180 ---> Loss 1.8216\n",
            "Iteration 190 ---> Loss 3.3911\n",
            "Iteration 200 ---> Loss 2.0365\n",
            "Iteration 210 ---> Loss 3.7345\n",
            "Iteration 220 ---> Loss 2.6522\n",
            "Iteration 230 ---> Loss 1.9828\n",
            "Iteration 240 ---> Loss 3.5046\n",
            "Iteration 250 ---> Loss 3.4611\n",
            "Iteration 260 ---> Loss 2.6047\n",
            "Iteration 270 ---> Loss 2.6107\n",
            "Iteration 280 ---> Loss 2.9071\n",
            "Iteration 290 ---> Loss 3.3612\n",
            "Iteration 300 ---> Loss 2.3992\n",
            "Iteration 310 ---> Loss 4.1753\n",
            "Iteration 320 ---> Loss 1.9403\n",
            "Iteration 330 ---> Loss 2.3248\n",
            "Iteration 340 ---> Loss 1.9111\n",
            "Iteration 350 ---> Loss 2.8922\n",
            "Iteration 360 ---> Loss 3.6746\n",
            "Iteration 370 ---> Loss 2.0209\n",
            "Iteration 380 ---> Loss 2.5574\n",
            "Iteration 390 ---> Loss 2.3497\n",
            "Iteration 400 ---> Loss 3.2784\n",
            "Iteration 410 ---> Loss 2.2053\n",
            "Iteration 420 ---> Loss 3.1153\n",
            "Iteration 430 ---> Loss 4.0538\n",
            "Iteration 440 ---> Loss 3.0235\n",
            "Iteration 450 ---> Loss 2.266\n",
            "Iteration 460 ---> Loss 2.0945\n",
            "Iteration 470 ---> Loss 3.0861\n",
            "Iteration 480 ---> Loss 2.2387\n",
            "Iteration 490 ---> Loss 2.9698\n",
            "Iteration 500 ---> Loss 4.0208\n",
            "Iteration 510 ---> Loss 1.7418\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-472350312.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_tokens_to_ids(\"[MASK]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB1BK2ZsLlxg",
        "outputId": "d84a61a2-435a-441a-d420-cee675e8ca9d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'تهران پاییتخت [MASK] است'\n",
        "model.eval();\n",
        "with torch.no_grad():\n",
        "  tokens= tokenizer(sentence,max_length=256,padding='max_length',truncation=True,return_tensors='pt');\n",
        "  item = {key:val.squeeze(0) for key,val in tokens.items()};\n",
        "  attention_mask = item['attention_mask'].unsqueeze(0).to(device);\n",
        "  input_ids = item['input_ids'].unsqueeze(0).to(device)\n",
        "  labels = torch.tensor([-100] * len(item['input_ids']),dtype=torch.int64).unsqueeze(0).to(device);\n",
        "  out = model(attention_mask = attention_mask,input_ids=input_ids,labels=labels);\n",
        "  logits = out.logits"
      ],
      "metadata": {
        "id": "L0ZGt02eG1Sw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cowCUKE6QXBC",
        "outputId": "56b820e9-bb64-41f9-f5cb-2d305c773fe5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2, 3326, 7859, 5516,    3, 2806,    4,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict = logits[0,4,:].argmax()"
      ],
      "metadata": {
        "id": "0amE9ZOwMujD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KZ4RSlINwiu",
        "outputId": "e3b2a75e-3b7f-4d7b-ba45-8e47624f69d6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2927, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens([predict])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqV3ACYfNWQT",
        "outputId": "ed75c64b-7f7e-48a8-def8-ed66c653f762"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ایران']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"انگلیس در قاره ی [MASK] واقع شده است\"\n",
        "model.eval();\n",
        "with torch.no_grad():\n",
        "  tokens= tokenizer(sentence,max_length=256,padding='max_length',truncation=True,return_tensors='pt');\n",
        "  item = {key:val.squeeze(0) for key,val in tokens.items()};\n",
        "  attention_mask = item['attention_mask'].unsqueeze(0).to(device);\n",
        "  input_ids = item['input_ids'].unsqueeze(0).to(device)\n",
        "  labels = torch.tensor([-100] * len(item['input_ids']),dtype=torch.int64).unsqueeze(0).to(device);\n",
        "  out = model(attention_mask = attention_mask,input_ids=input_ids,labels=labels);\n",
        "  logits = out.logits\n",
        "input_ids = input_ids.squeeze(0);\n",
        "masks = torch.tensor([i for i in range(len(input_ids)) if input_ids[i].item()==3])\n",
        "predict = logits[0,masks,:].argmax()\n",
        "tokenizer.convert_ids_to_tokens([predict])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aGXqCTkNaGB",
        "outputId": "a021d9e3-566a-4fcf-f9f3-87889a767dc5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['اسیا']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.squeeze(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIQdC_GrSevC",
        "outputId": "61d59e6b-50d3-4218-eb1d-6b1a855b6ff2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2, 5853, 2786, 8080, 1442,    3, 3473, 2871, 2806,    4,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(input_ids.squeeze(0))):\n",
        "  print(input_ids.squeeze(0)[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiklCYxIRdGz",
        "outputId": "df565ce8-6207-48af-f738-308d03391ad4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2, device='cuda:0')\n",
            "tensor(5853, device='cuda:0')\n",
            "tensor(2786, device='cuda:0')\n",
            "tensor(8080, device='cuda:0')\n",
            "tensor(1442, device='cuda:0')\n",
            "tensor(3, device='cuda:0')\n",
            "tensor(3473, device='cuda:0')\n",
            "tensor(2871, device='cuda:0')\n",
            "tensor(2806, device='cuda:0')\n",
            "tensor(4, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}